En la literatura se pueden encontrar trabajos que abordan la noción de recuperación de información con diferentes semánticas. Por ejemplo, en \cite{BasuRoy:2010:CEC:1807167.1807258} se plantea devolver información complementaria de un ``ítem central'' (\textit{composite item}). La información que se obtiene es un conjunto de ``paquetes satélites'', que son conjuntos de ítems de diferente tipo al ``ítem central'' pero a su vez son compatibles. Un escenario de aplicación podría ser: un comprador de un teléfono celular (ítem central) que dispone de cierto presupuesto al que se le ofrecen paquetes que incluyen otros items relacionados como funda, tapa, parlantes, cargador, etc. Lograr el objetivo implica identificar todos los paquetes satélites válidos y maximales a partir de un ítem central. Un paquete maximal y válido significa un conjunto de elementos los cuáles respetan un presupuesto, son compatibles con el ítem central y no son un subconjunto de otro paquete válido. 

Para la construcción de los paquetes satélites se utiliza un algoritmo que elige aleatoriamente ítems que sean compatibles con el ítem central y cumpla las restricciones de presupuesto y validez. Luego implementan algoritmos voraces basados en técnicas de clustering para lograr el mejor cubrimiento de los paquetes encontrados.

En \cite{Xie:2010:BOB:1864708.1864739} sugiere que el resultado de un sistema de recomendación debería ser un conjunto de paquetes y no una clásica lista ordenada por los ítems más relevantes. Consideran que muchas aplicaciones se beneficiarían al utilizar este criterio. Por ejemplo, podría aplicarse para un turista que está interesado en sugerencias de lugares o puntos de interés para su viaje, dispone de determinado tiempo y presupuesto y maneja una noción de compatibilidad entre items (a lo sumo 3 museos, recorrido menor a cierta distancia, etc). Si cada atracción tiene asociado un ranking, la idea es ofrecer los mejores $k$ paquetes de atracciones de tal manera que en cada paquete se respete el presupuesto y la compatibilidad entre items.

La solución -se trata de un problema NP-completo- que propone se obtiene a partir de una variación del  algoritmo utilizado para resolver el problema de la mochila para valores enteros. 

Si bien el objetivo de ambos trabajos es entregar conjuntos de ítems relacionados que generan un valor agregado al usuario de la aplicación, ninguno tiene en cuenta la diversidad entre los paquetes sugeridos. formalizando la recuperación de la información como un problema de {\em clustering} que sólo considera la compatibilidad entre items. Como alternativa, en \cite{compositeRetrival} se propone conjugar en el conjunto de paquetes sugeridos al usuario las nociones de diversidad, similitud y compatibilidad dependiendo de la necesidad y elección del usuario.

A continuación se describen brevemente las características de los algoritmos propuestos en \cite{compositeRetrival}.

\begin{itemize}

\item {\em Produce and Choose} (PAC): Utiliza un esquema de dos fases, donde en la primera se producen paquetes válidos y en la segunda se eligen $k$ entre ellos. Para la producción de paquetes se implementaron dos algoritmos de {\em clustering}, uno basado en {\em clustering} jerárquico aglomerativo (C-HAC) y el segundo en {\em k-means clustering} (BOBO, por Bundles One-By-One). Para la segunda fase se adaptaron heurísticas de la literatura para el problema {\em Maximum Edge Subgraph}.

En C-HAC inicialmente cada ítem forma un {\em cluster} unitario y luego sucesivamente en cada iteración se elige un par de {\em clusters} para ser unidos y generar un {\em cluster} válido, es decir que cumpla las restricciones de complementariedad y no supere el presupuesto $\beta$. El algoritmo finaliza cuando no existe un par de {\em clusters} que pueda ser unido en un {\em cluster} válido o se alcance una condición de parada (por ejemplo número de {\em clusters} generados). Como criterio de elección de los {\em clusters} a unir se busca maximizar la función $Score$, que es la suma de las similitudes de todos los items del par candidato. Este criterio de unión sólo presta atención a la similitud intra-paquete, lo que hace que, cuando se busca una alta diversidad, el conjunto de paquetes generados de esa forma no sea necesariamente bueno.

El método \texttt{BOBO-c}, está inspirado en k-means. En términos simples, consiste en generar $c*k$ {\em clusters} del conjunto de $n$ items. El algoritmo comienza con todos los items del conjunto $I$ como posibles \emph{pivotes} $P$. Se selecciona un pivote de $P$ y con los elementos de $I$ se genera un {\em cluster} válido ``alrededor" de éste. En caso que el {\em cluster} generado sea suficientemente bueno (su valor intra supera un parámetro $\mu$) se agrega al conjunto de paquetes candidatos y los items del {\em cluster} se eliminan de $P$. La generación de {\em clusters} continúa hasta que se cumpla el criterio de parada que es la generación de $c*k$ {\em clusters}. Con BOBO-c pueden quedar items excluidos de los paquetes generados, por lo que se desarrolló una variante del método, llamado BOBO-E' (por Exhaustivo) que logra que todos los items pertenezcan a un paquete. Para esta producción se modificó el criterio de parada hasta que el conjunto de pivotes $P$ sea vacío. Para grandes bases de datos los tiempos de ejecución de esta variante BOBO-E' resulta impracticable.

Al finalizar la producción de paquetes comienza la etapa de selección, en la cual se deben seleccionar los $k$ paquetes que formarán la solución (Selección simple). El problema de seleccionar los paquetes que maximizan la función objetivo se traduce en encontrar en un grafo completo $G$ cuyos vértices representan los paquetes (con pesos asociados dados por sus valores intra) y cuyas aristas tienen como peso los valores inter, el subgrafo de $k$ vértices de mayor peso (considerando los pesos de los vértices y aristas). Para ello se implementó un algoritmo goloso, en el cual se selecciona iterativamente del conjunto de paquetes aquél que maximiza la función objetivo evaluada en los paquetes hasta el momento seleccionados. Al notar que en las primeras iteraciones de esta selección el valor inter-paquetes es despreciable con respecto a la suma de los valores intra-paquete. Esto hace que cuando se quiere privilegiar la diversidad de paquetes en la solución (valores bajos de $\gamma$) ésta no sea una buena estrategia.

Como consecuencia de la forma en que las soluciones son generadas en las heurísticas del tipo {\em Produce and choose} (construir una cantidad suficiente de paquetes y luego seleccionar un subconjunto de éstos), es de esperar que las soluciones generadas se enfoquen más en valorar la parte intra-paquete que la inter-paquetes.

\item {\em Cluster and Pick} (CAP): Sigue un esquema de dos fases. En la primera se busca un $k$-{\em clustering} (un {\em cluster} no es necesariamente un paquete válido) y luego en la segunda se selecciona un paquete válido de los {\em clusters} generados en la primera etapa.

\item Método IP: Se presenta un modelo de programación lineal entera que resuelve el problema de forma exacta. Los tiempos de ejecución de este enfoque lo hacen prohibitivo para grandes instancias.

\end{itemize}

Los algoritmos propuestos son evaluados en \cite{compositeRetrival} sobre dos bases de datos reales. Una de ellas se refiere a atracciones turísticas en 10 ciudades europeas, donde por cada una de estas instancias se consideran 20 atracciones. El segundo conjunto de datos se compone de opiniones sobre restaurantes en 149 ciudades proveniente de Yahoo! Local. El número de restaurantes en cada ciudad varía de 300 a 2000.

De la experimentación presentada en \cite{compositeRetrival}, se concluye que las mejores soluciones se obtienen con los algoritmos que primero agrupan los ítems en paquetes válidos y luego seleccionan paquetes dentro de este agrupamiento (PAC). 
