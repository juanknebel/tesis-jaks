\section{Modelo}
Dado el conjunto de documentos $I$ y una función de similitud $ s: I x I \rightarrow [0;1]$, cada documento es unívocamente identificado y contiene un conjunto de atributos. La entrada puede pensarse como un grafo completo con peso en las aristas $G=(I,E,s)$ donde el peso del vértice $(u,v)$ es $s(u,v)$. Se define también la \textit{función de distancia} $d(u,v) = 1 - s(u,v)$ que también toma valores en el intervalo $[0;1]$. 

\section{Problema}
El problema consiste en devolver un conjunto de bundles $S = \left\{s_1, \ldots, s_k\right\}$ donde el bundle $S_i \in 2^{I}$ es un conjunto de documentos que satisface las reglas de \textit{complementaridad} y \textit{presupuesto}.\\
\textbf{Definción} Dado el conjunto de documentos $I=\left\{i_1,\ldots, i_n\right\}$ el bundle $S \in 2^{I}$ es valido si solo si satisface las reglas:
\begin{itemize}
	\item \textbf{Complementaridad:} dada la propiedad $\alpha$ de los documentos, $\forall u,v \in S_i, u.\alpha \neq v.\alpha$
	\item \textbf{Presupuesto:} dada la función de costo $f$ y el presupuesto $\beta$, entonces $\forall S_i \in S, f(S_i) \leq \beta$
\end{itemize}

La definición formal de \textit{Composite Retrieval} es:\\
Dado el conjunto de documentos $I = \left\{i_1, \ldots, i_n \right\}$, la función de similitud $s(u,v)$, el atributo complementario $\alpha$, la función de costo $f$, el presupuesto $\beta$ y el entero $k$ se desea hallar el conjunto valido de bundles $S = \left\{s_1, \ldots, s_k\right\}$ que maximiza la función:
	
	\begin{equation}
		\sum_{1 \leq i \leq k}{\sum_{u,v \in S_i}{\gamma s(u,v)}} + \sum_{1 \leq i \leq j \leq k}{(1-\gamma) (1-)\max_{u \in S_i, v \in S_j}{s(u,v)}}
	\end{equation}
	
En \cite{compositeRetrival} se demuestra que la complejidad de devolver $k$ bundles de items complementarios con un presupuesto es NP-Completo. Para obtener una solución se realizaron los algoritmos de aproximación Produce-and-Choose y uno goloso. Produce-and-Choose consiste en dos etapas, la primera en producir varios bundles validos y una segunda etapa de selección de los bundles.

\section{Función de similitud}
La similitud se emplea para comparar dos documentos y determinar qué tan parecido son entre si. La comparación se realiza en el \textit{modelo de espacio vectorial} donde los artículos se representan con vectores, en la que cada dimensión corresponde a un tópico. El valor del tópico del artículo de la base de datos \cite{dataDrive}, es el valor en el vector.\\
El artículo $a$ se representa con el vector $V_a = [v_1,v_2,...,v_n]$, donde $N$ es la cantidad de tópicos. Los vectores cumplen con las propiedades:
\begin{enumerate}
 \item $v_i \leqslant 1$
 \item $\sum{v_i} = 1$
\end{enumerate}

Con los vectores es posible calcular el coeficiente de similitud a través de la función $ S (V_i, V_j)$ la cual refleja el grado de similitud de los pesos de los tópicos correspondientes. Existen varias medidas de similitud, En este trabajo se utilizó una de las más utilizadas que es la medida de similitud basada en el ángulo de los vectores.\\
En la medida de similitud del coseno la dirección de los vectores es lo que se utiliza para determinar qué tan parecidos son entre si. Cuanto más parecido sean los documentos el ángulo de los vectores se acerca a cero. Siendo que dos vectores con idéntica distribución de los términos, el ángulo es cero, produciendo la máxima medida de similitud.\\
Conforme a \cite{newSimilarity} el ángulo de dos vectores proporcionales tiene la misma dirección con lo que el ángulo es cero. Entonces estos vectores son exactamente similares en cuanto a la medida de similitud basada en el ángulo. Esta medida no considera el peso de cada tópico. Por lo tanto no diferencia entre un artículo profesional y un artículo de un diario que cubre el mismo tópico. Esta debilidad de la medida basada en el ángulo no interfiere en este trabajo, por las propiedades de los vectores los documentos. Porque los documentos con tópicos similares se representan con vectores que se encuentran muy cerca en el espacio euclidiano. Dado los vectores $V_i$ y $V_j$ la función de similitud basada en el ángulo se obtiene por la definición del producto escalar.\\

\begin{equation} \label{eq:angulovectorial}
\cos(\theta) =  \dfrac{\overrightarrow{U} . \overrightarrow{V}}{\overrightarrow{\lVert V\lVert}.\overrightarrow{\lVert U\lVert}}
\end{equation}

Como los componentes de todos los vectores son mayor o igual a cero se obtiene que $0\leq\cos(\theta)\leq1$. Que corresponde con la función de similitud.

\begin{figure}[H]
\includegraphics[width=0.8\textwidth]{img/coseno.png}
\caption{Comportamiento de la función $\cos$. En rojo la región que involucra los resutlados de la función de similitud}
\label{bus:img-coseno}
\end{figure}


\section{Produce-and-Choose}
El algoritmo para aproximar a la solución \texttt{Produce-and-Choose}, Consiste en dos fases. En la primer fase se generan cierta cantidad de bundles, en la fase siguiente se seleccionan los bundles que serán parte de la solución.\\
A continuación se explican los algoritmos utilizados para cada fase.
\subsection{Generación de bundles}
Dado un conjunto de papers el objetivo es generar clusters en los cuales los papers suficientemente similares pertenezcan al mismo cluster y en cluster distintos los disímiles. Cuanto mayor es la similitud en el cluster (intra) y mayor la diferencia entre los cluster (inter) es mejor la clusterización.\\
Definir como se constituye un cluster es complejo. Por ejemplo para los 20 puntos que se muestran a continuación existen tres (o más) formas de clusterizar que son válidas. Entonces la mejor definición depende del tipo de dato y del resultado esperado.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.8\textwidth]{img/howToCluster.png}
  \caption{Agregar descripcion}
  \label{res:img-howToCluster}
\end{figure}

En la clusterización para Composite Retrival, la definición es generar cada cluster maximizando el costo que esta acotado por el budget. Ya que lo esperado es obtener cluster que utilicen el máximo del presupuesto.\\
El problema de la clusterización es NP-hard (agregar ref, explicar problema de clusterizacion), por lo que se utilizaron dos técnicas ya conocidas para aproximarse a una solución. La principal diferencia entre las estrategias de clusterización es entre la jerárquica y de partición.\\
La primer técnica produce un árbol de particiones, la raíz es un cluster que contiene todos los ítems y las hojas son clusters con un único ítem. Cada nivel intermedio, puede ser visto, como la combinación entre dos clusters del nivel inferior inmediato. Mientras que la segunda genera solo un nivel de las particiones de los items de una vez.\\ 
Se implementaron las dos técnicas. La clusterización jerárquica con el algoritmo Hierarchical clustering y la de partición con Bundles One-By-One.\\

\subsubsection{Bundles One-By-One}
El método \texttt{BOBO-x} está inspirado en k-nn. Consiste en cada paso seleccionar, de manera azarosa, un ítem del conjunto de pivotes (en el inicio este conjunto contiene todos los ítems), con el que se genera un bundle valido a alrededor de este. En el caso de que el intra del bundle sea bueno se agrega al conjunto de candidatos de bundle. La iteración finaliza cuando se generan la cantidad de candidatos definidos en el parámetro $x$ o cuando el conjunto de bundles es vacío. Para el caso de que $x$ sea 'Ex' todos los items son pivotes.\\
Para generar el bundle a partir del pivote, se realiza de manera golosa de eligiendo en cada iteración el ítem que maximiza el intra y que cumple con las restricciones.\\

\subsubsection{Hierarchical clustering}
La heurística Hierarchical clustering \texttt{HAC} comienza con tantos clusters como cantidad de elementos, cada uno está conformado por un solo ítem y en cada paso se unen los dos clusters más cercanos que respetan las restricciones. Para ello se define la función de distancia para los ítems $u$ y $v$ como:\\

\begin{equation}
d_{1}(u,v) = 1 - s(u, v)
\end{equation}

Con la función de distancia $d_{1}$ en la clusterización se generan los cluster lo más cohesivos posibles, En la figura 1 se observa que el algoritmo selecciona los ítems más cercanos. En las búsquedas que se realizan en \cite{compositeRetrival} se tiene el parámetro $\gamma$ que indica que tipo de resultado es el esperado.

\begin{figure}[H]
  \centering
    \includegraphics[width=0.3\textwidth]{img/cluster2.png}
  \caption{Selección de bundles usando $d_{1}$}
  \label{res:img-usingEfficientHAC}
\end{figure}

En caso de que el $\gamma$ sea pequeño, la clusterización esperada para la misma instancia es la que se visualiza en la imagen 2, clusters no tan cohesivos pero más variados. Por lo que se define una función de distancia que considera el $\gamma$.\\

\begin{equation}
d2(u,v) = 1 - FO(\{u\} \cup \{v\})
\end{equation}
Donde $FO$ es la función definida en \eqref{eq:fnObj} \\

\begin{figure}[H]
  \centering
    \includegraphics[width=0.3\textwidth]{img/cluster1.png}
  \caption{Selección de bundles usando $d_{2}$}
  \label{res:img-usingSingleHAC}
\end{figure}

Para la distancia $d_{1}$ se implementó el algoritmo \texttt{EfficientHAC} que es tiene una complejidad $\mathcal{O}(n^{2})$, mientras que para $d_{2}$ el algoritmo es \texttt{SingleHAC} que la complejidad es $\mathcal{O}(n^{2} * \ln{n})$. Según se demostró en el capítulo 17 de \cite{informationRetrival}.


\subsection{Selección de bundles}
Al finalizar la producción de bundles, se deben seleccionar los $k$ bundles para la solución. El problema de seleccionar los bundles que maximizan la función objetivo, se traduce en encontrar en el grafo G el k-subgrafo de mayor peso de nodos y vértices. Dónde el peso de los nodos representa la calidad de los bundles y el peso de las aristas es la distancia entre los nodos.\\
Formalmente el problema de encontrar el subgrafo de máximo peso de nodos y vértices con k nodos, consiste en dado el grafo $ G = (V,E) $, la funciones de peso $\psi : E \rightarrow \Re$ y $\omega : V \rightarrow \Re$, el entero $ k \leq |V| $ y el real $\gamma \in [0,1]$. La salida es el conjunto $V' \subseteq V$ tal que $|V'| = k$ que maximiza el peso de los nodos y vértices del subgrafo $G' = (V', E')$ ponderado por el parámetro $\gamma$.

\begin{equation}
\gamma \sum_{v \in V'}{\omega(v)} + (1 - \gamma) \sum_{(u,v) \in E'}{\psi(u,v)}
\end{equation}

El problema de encontrar el máximo k-subgrafo con pesos en los nodos y vértices, se puede reducir al problema ya conocido de hallar el k-subgrafo más denso\cite{SubgraphProblem}. Transformando en la instancia del problema original la función del peso de los vértices por:
 
\begin{equation}
\omega(u,v) = \dfrac{\gamma}{2( k - 1)} (\omega(u) + \omega(v)) + (1 - \gamma)\psi(u,v) 
\end{equation}

A esta nueva instancia del problema, se le aplica la heurística golosa en la que en cada iteración se remueve el nodo con menos peso en las aristas.\\

(aca va el algoritmo)\\

Otra heurística propuesta para la selección, también goloso, consiste en seleccionar en cada iteración un bundle para la solución. Sea $B$ el conjunto de bundles producidos, $S \subseteq B$ el conjunto de bundles seleccionados, en la iteración $i$ se agrega a la solución el bundle que cumple con:

\begin{equation}
\max_{b \in (B/S)}{\dfrac{k}{|S|}} \gamma \sum_{v \in \left\{b\right\} \cup S}{\omega(v)} + \dfrac{k * (k-1)}{|S| * (|S|-1)} (1-\gamma) \sum_{v,w \in \left\{b\right\} \cup S}{\psi(v,w)}
\end{equation}

\begin{algorithm}[H]
\begin{algorithmic}[1]
\REQUIRE $produced:Vector<SnowFlake>, numRequested:Integer$
\ENSURE $selected:Vector<SnowFlake>$
\STATE $w(u) = \dfrac{k}{u.size} * (\gamma \sum_{v \in U}(w(v))) + \dfrac{(k * (k-1))}{2} * \dfrac{2}{(u.size() * (u.size() - 1))} * 1 - \gamma \sum_{v,w \in U}(\psi(v,w))$
\STATE $available \leftarrow produced$
\STATE $selected \leftarrow []$
\WHILE {$selected.size < numRequested\ AND\ selected.size < produced.size$}
\STATE $candidate \leftarrow max_{i}$
\ENDWHILE
\RETURN $selected$
\end{algorithmic}
\caption{Selección de bundles proporcional}\label{alg:algSelProp}
\end{algorithm}

\section{Algoritmo goloso}
En los algoritmos previos se centraron en construir bundles maximizando el intra y una vez generado una cantidad suficiente seleccionar un conjunto de estos para la solución. En el algoritmo goloso propuesto, se generan únicamente los bundles que pertenecen a la solución. Agregando iterativamente el item al bundle que maximiza la función objetivo.\\
El algoritmo comienza con los bundles de la solución vacíos. En cada paso selecciona, de los items que no son parte de la solución, aquel que máximiza la función objetivo agregándolo a alguno de los bundles sin violar las restricciones del problema.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\REQUIRE $numOfSnowFlakes:Integer$
\ENSURE $selected:Vector<SnowFlake>$
\STATE $selected_{i}:Vector<SnowFlake> \leftarrow \emptyset_{0\leq i<numOfSnowFlakes}$
\STATE $isComplete:Bool \leftarrow False$
\STATE $elements:Set<Element> \leftarrow ElementsOfTheProblem$
\WHILE {$isComplete == False$}
  \STATE $bestScore:Double \leftarrow -\infty$
  \STATE $bestElement:Element \leftarrow \varnothing$
  \STATE $bestBundle:SnowFlake \leftarrow \varnothing$
  \FOR {$elem:Element \in elements$}
    \FOR {$bundle:SnowFlake \in selected$}
      \IF {$isValidBundle(bundle \cup \{elem\}) == True$}
        \STATE $score:Double \leftarrow FO(selected.replace(bundle, bundle \cup \{elem\}))$
        \IF {$score > bestScore$}
          \STATE $bestScore \leftarrow score$
          \STATE $bestBundle \leftarrow bundle$
          \STATE $bestElement \leftarrow elem$
        \ENDIF
      \ENDIF
    \ENDFOR
  \ENDFOR
  \STATE $selected \leftarrow selected.replace(bundle, bundle \cup \{elem\})$
  \STATE $elements.erase(elem)$
  \STATE $isComplete \leftarrow bestElement == \varnothing$
\ENDWHILE
\RETURN $selected$
\end{algorithmic}
\caption{Algoritmo heurística golosa}\label{alg:algHeuGol}
\end{algorithm}

\section{Búsquedas Tabú}
Las búsquedas locales consisten en moverse de solución en solución, aplicando cambios a la solución candidata hasta encontrar una mejor solución o satisfacer un criterio de parada. Los algoritmos consisten en comenzar con una solución e iterativamente moverse a una solución vecina, esto es posible solo si se pude definir una relación de vecindad en el espacio de búsqueda. Como una solución puede tener muchas soluciones vecinas se elige siempre la que maximice o minimice (según el problema elegido) el criterio seleccionado, esto produce que el algoritmo pueda estancarse en un mínimo (ó máximo) local y nunca pueda salir de él.\\
\textbf{Tabú search} es una metaheurística, de la familia de las búsquedas locales, que relaja la primer regla de las búsquedas locales tradicionales y permite moverse a una solución vecina que no cumple con el criterio de búsqueda. De esta manera se permite al algoritmo escapar de máximos o mínimos locales y encontrar una mejor solución (en caso que existiese). Otras de las modificaciones que se agregan es que una vez que una solución determinada es visitada, se la marca como tabú para que no vuelva a ser visitada por una determinada cantidad de iteraciones para también de esta manera evitar caer en ciclos y mínimos o máximos locales.\\
Una de las ventajas que tienen este tipo de metaheurísticas es que no son muy costosas en tiempo de ejecución siempre que la cantidad máxima de iteraciones no sea excesiva, con lo cual se puede ejecutar sin problemas y sin importar el algoritmo de generación y selección provenga la solución orginal con el fin de intentar mejorarla.\\
Se implementaron las búsquedas tabú Inter-Bundle e Intra-Bundle. La primera busca encontrar una mejor solución entre la solución actual y los bundles ya generados; la otra consiste en mejorar los bundles con los items que quedaron fuera de la solución.

\subsection{Inter-Bundle}
La búsqueda se concibió especialmente para la fase de selección del algoritmo \texttt{Produce-and-Choose}. En esta fase se eligen los bundles que pertenecen a la solución. De la solución obtenida se realiza la búsqueda tabú con los bundles generados en la fase del produce con el objetivo de recorrer las soluciones con bundles menos cohesivos entre si.\\
Los movimientos de la solución $S$ a la solución $S'$ consiste de los siguientes  pasos:
\begin{enumerate}
	\item Obtener el Bundle de la solución a reemplazar.
	\item Determinar el bundle centroide de la solución.
	\item Agregar a la solución el bundle más alejado al centroide.
\end{enumerate}

Sea $S$ el conjunto de bundles de la solucion y B el conjunto de todos los bundles producidos. El bundle (1) es el más acoplado al de la solución $b_r = \min_{b_1 \in S}{\sum_{b_2 \in S}{\psi(b_1,b_2)}}$. El centroide de (2) es el bundle que tiene mayor similitud entre los bundles de la solución, sin tener en cuenta al bundle a reemplazar, entonces el centroide es $b_c = \min_{b_1 \in S \setminus \left\{b_r\right\}}{\sum_{b_2 \in S \setminus \left\{b_r\right\}}{\psi(b_1,b_2)}}$. El bundle de (3) se obtiene de $b_n = \min_{b_1 \in S \setminus \left\{b_r\right\}}{\psi(b_1,b_c)}$. Por lo tanto la nueva solución es $S' = (S \setminus \left\{b_r\right\}) \cup \left\{b_n\right\}$. Mientras que el bundle $b_r$ se marca para que no sea seleccionado para las próximas soluciones generadas.
\begin{algorithm}[H]
\begin{algorithmic}[1]
\REQUIRE $aSolution: Vector<SnowFlake>, remainingBundles: Vector<SnowFlake>, gamma: Double$
\ENSURE $newSolution:Vector<SnowFlake>$
\STATE $iteration:Integer \leftarrow 0$
\STATE $tabuBundles: Set<SnowFlake>$
\STATE $bestSolution: Vector<SnowFlake> \leftarrow aSolution$
\STATE $bestFunction:Double \leftarrow FO(bestSolution)$
\STATE $tempSolution: Vector<SnowFlake> \leftarrow bestSolution$
\WHILE {$iteration < MAX\_ITER$}
  \STATE $updateTabuCount(tabuBundles)$
  \STATE $iterationSolution: Vector<SnowFlake> \leftarrow tempFunction$
  \STATE $worstBundle: SnowFlake \leftarrow$\\
  $getWorstBundle(iterationSolution, tabuBundles)$
  \STATE $centroidBundle: SnowFlake \leftarrow findCentroid(iterationSolution)$
  \STATE $bestBundles: Set<SnowFlake> \leftarrow findBestBundles(centroidBundle, remainingBundles, tabuBundles)$
  \STATE $interFunction: Doubel \leftarrow calculateInter(iterationSolution)$
  \FOR {$aBundle \in bestBundles$}
    \STATE $iterationSolution.replace(worstBundle, aBundle)$
    \STATE $newInterFunction \leftarrow calculateInter(iterationSolution)$
    \IF {$newInterFunction > interFunction$}
      \STATE $betterSolution: Bool \leftarrow True$
      \STATE $saveSolution$
    \ELSE
      \IF {$not betterSolution$\\
           $and\ otherFunction\ is\ better\ than\ others\ functions$\\
           $and\ aBundle\ was\ tabu\ before$}
        \STATE $bestWorstSolution: Bool \leftarrow True$
        \STATE $saveSolution$
      \ENDIF
    \ENDIF
  \ENDFOR
  \IF {$betterSolution$}
    \STATE $replace\ tempSolution\ with\ saved\ solution$
    \STATE $newFunction: Double \leftarrow FO(tempSolution)$
    \IF {$newFunction > bestFunction$}
      \STATE $bestSolution \leftarrow tempSolution$
    \ENDIF
  \ELSE
    \IF {$bestWorstSolution$}
      \STATE $replace\ tempFunction\ with\ saved\ solution$
    \ENDIF
  \ENDIF
  \STATE $tabuBundles \leftarrow tabuBundles \cup {worstBundle}$
\ENDWHILE
\STATE $newSolution \leftarrow bestSolution$
\RETURN $newSolution$
\end{algorithmic}
\caption{Algoritmo búsqueda tabú sobre bundles}\label{alg:algBusTabuBundle}
\end{algorithm}

\subsection{Intra-Bundle}
En Intra-Bundle explora soluciones con bundles más cohesivos. De la solución actual se realiza el movimiento a una nueva solución con los pasos:
\begin{enumerate}
	\item Obtener el bundle menos cohesivos de la solución.
	\item Determinar el centroide del bundle.
	\item Hallar el ítem más alejado del centroide.
	\item Reemplazar con el ítem, que no pertenece a la solución, más cercano al centroide.
\end{enumerate}

Sea $S$ el conjunto de bundles de la solución e $I$ el conjunto de ítems, el bundle de (1) es $b = \min_{b_1 \in S}{\sum_{v,w \in b_1}{s(v,w)}}$. De $b$ se define el centroide $c$ del paso (2) con $c = \max_{v \in b}{\sum_{w \in b}{s(v,w)}}$. El item de (3) se obtiene de $i = \min_{v \in b}{s(v,c)}$. El item para reemplazar a $i$ es $j = \max_{v \in I \setminus items(S)}{s(v,c)}$. Por lo que la nueva solución se define $S' = (S \setminus \left\{b\right\}) \cup \left\{(b \setminus \left\{i\right\})\cup\left\{j\right\}\right\}$

\begin{algorithm}[H]
\begin{algorithmic}[1]
\REQUIRE $aSolution: Vector<SnowFlake>, gamma: Double$
\ENSURE $newSolution:Vector<SnowFlake>$
\STATE $iteration:Integer \leftarrow 0$
\STATE $tabuBundles: Set<SnowFlake>$
\STATE $tabuElements: Set<Element>$
\STATE $bestSolution: Vector<SnowFlake> \leftarrow aSolution$
\STATE $bestFunction:Double \leftarrow FO(bestSolution)$
\STATE $tempSolution \leftarrow bestSolution$
\WHILE {$iteration < MAX\_ITER$}
  \STATE $updateTabuCount(tabuBundles)$
  \STATE $updateTabuCount(tabuElements$
  \STATE $bundeWithWorstInter: SnowFlake \leftarrow$\\
  $findWorstIntraBundle(tempSolution, tabuBundles)$
  \STATE $centroid: Element \leftarrow findCentroid(bundeWithWorstInter)$
  \STATE $farAwayElement: Element \leftarrow$\\
  $findFarAwayElement(centroid, bundeWithWorstInter)$
  \STATE $bestElements: Set<SnowFlake> \leftarrow$\\
  $nearestElements(centroid, farAwayElement, bundeWithWorstInter, tabuElements)$
  \STATE $tempFunction: Double \leftarrow FO(tempSolution)$
  \FOR {$near:Element \in bestElements$}
    \STATE $newBunlde: SnowFlake \leftarrow bundeWithWorstInter.replace(farAwayElement, near)$
    \STATE $otherSolution: Vector<SnowFlake> \leftarrow$\\
    $tempSolution.replace(bundeWithWorstInter, newBunlde)$
    \STATE $otherFunction: Double \leftarrow FO(otherSolution)$
    \IF {$otherFunction > tempSolution$}
      \STATE $betterSolution: Bool \leftarrow True$
      \STATE $saveSolution$
    \ELSE
      \IF {$not betterSolution$\\
           $and\ otherFunction\ is\ better\ than\ others\ functions$\\
           $and\ bundeWithWorstInter\ was\ tabu\ before$}
	\STATE $bestWorstSolution: Bool \leftarrow True$
	\STATE $saveSolution$
      \ENDIF
    \ENDIF
  \ENDFOR
  \IF {$betterSolution$}
    \STATE $replace\ tempSolution\ with\ saved\ solution$
    \STATE $newFunction: Double \leftarrow FO(tempSolution)$
    \IF {$newFunction > bestFunction$}
      \STATE $bestSolution \leftarrow tempSolution$
    \ENDIF
    \STATE $tabuElements \leftarrow tabuElements \cup {farAwayElement}$
  \ELSE
    \IF {$bestWorstSolution$}
      \STATE $replace\ tempSolution\ with\ saved\ solution$
      \STATE $tabuElements \leftarrow tabuElements \cup {farAwayElement}$
    \ENDIF
  \ENDIF
\ENDWHILE
\STATE $newSolution \leftarrow bestSolution$
\RETURN $newSolution$
\end{algorithmic}
\caption{Algoritmo búsqueda tabú sobre elementos}\label{alg:algBusTabuIntra}
\end{algorithm}
